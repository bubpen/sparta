# 머신러닝 개인과제

## 1. 지도학습 모델

### 1.1 데이터 전처리
  - 결측치를 중앙값으로 대체.
  - 결측치를 모두 제거.
    - 결측치를 제거한 데이터와 결측치를 처리한 데이터를 비교하고자 진행.
  - 이후 두 데이터 모두 이상치를 IQR 방법을 사용하여 범위를 넘어가는 데이터에 upper_bound, lower_bound 값으로 대체
  - 컬럼 중 'CHAS', 'AGE', 'B' 컬럼을 제거하여 데이터를 전처리
  - 데이터를 모두 StandardScaler를 사용하여 정규화

### 1.2 모델 학습 및 평가
  - 선형회귀 모델과 의사결정나무 모델, 랜덤 포레스트 모델을 사용하여 모델을 학습
  - 결측치를 제거하지 않은 데이터를 사용한 학습에서는 랜덤 포레스트 모델이, 결측치를 제거한 데이터를 사용한 학습에서는 의사결정나무 모델의 성능이 가장 좋은 것을 확인할 수 있었다.
  - 총 6가지의 경우를 확인한 결과, 결측치를 제거하지 않은 데이터를 사용한 랜덤 포레스트 모델의 학습의 성능이 가장 좋은 것을 확인할 수 있었다.

### 1.3 도전 과제
  1. 모델 앙상블
    1.1  배깅 부스팅 모델을 사용
      - 배깅 모델로 BaggingRegressor 모델을 사용
      - 부스팅 모델로 GradientBoostingRegressor, XGBoostingRegressor 모델을 사용
    1.2 모델 평가
      - GradientBoostingRegressor 모델은 파라미터를 변경해가며 학습을 시도했고, max_dapth를 5로 설정하였을 때, R2 score가 0.9 이상으로 나오는 것을 확인할 수 있었다.
      - 성능은 R2 score로 비교하여, XGBoostingRegressor 모델이 가장 좋은 성능을 확인할 수 있었다.

  2. 하이퍼파라미터 튜닝
    1.1 GridSearchCV를 사용한 하이퍼파라미터 튜닝
      - 모델은 GradientBoostingRegressor 모델을 사용.
      - 파라미터는 max_depth, learning_rate, n_estimators를 사용하여 튜닝.
      - R2 score가 이전 학습보다 낮은 이유는 k-fold 교차검증을 사용하여 진행했기에 평균값으로 나온 것이다.

  3. 시간적 요소 추가
    - 세금이 비율이므로 세금이 올라갈 때마다 연도가 늘어난다고 생각을 해서 연도를 나타내는 'YEAR'이라는 컬럼을 추가해서 가장 성능이 높게 나왔던 랜덤 포레스트 모델에 학습을 시켜보았다.


## 2. 비지도학습 모델

### 2.1 데이터 전처리
  - 비지도 학습에 사용된 데이터에는 결측값이 없었고, 이상치도 눈에 띄는 값이 없어 범주형 데이터를 원-핫 인코딩을 사용해 전처리를 진행

### 2.2 모델 학습 및 평가
  - KMeans 모델과 계층적 군집화 모델, DBSCAN 모델을 사용
    - 엘보우 방법을 사용하여 최적의 클러스터 수를 찾아 6으로 설정
  - DBSCAN 모델은 파라미터 값들을 변경하며 실루엣 계수를 확인하였지만, 제일 높은 실루엣 계수가 0.01로 나온다.
  - 성능이 가장 좋은 모델은 실루엣 계수가 0.33으로 나온 KMeans 모델이다

### 2.3 도전 과제
  - 다양한 클러스터링 기법 비교
    - 다른 클러스터링 기법으로 Gaussian Mixture Model (GMM)을 사용
      - GMM 모델은 covariace_type을 'full', 'tied', 'diag', 'spherical' 중 선택을 하며 'full'은 완전 공분산으로 가장 유연하지만 많은 파라미터를 요구하고, 'tied'는 묶인 공분산으로 데이터가 비슷한 모양의 클러스터를 가질 때 사용, 'diag'는 대각 공분산으로 축 방향으로 분포된 데이터일 때 사용, 'spherical'은 구형 공분산을 뜻하며 원형 클러스터가 예상될 때 사용되며 일반적으로 'full'로 시작하고 필요에 따라 다른 타입을 시도한다.
    - 위 모델들과도 비교한 결과, 실루엣 계수가 0.33으로 나온 KMeans 모델이 가장 좋은 성능을 확인할 수 있었다.